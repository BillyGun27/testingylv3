Train on 2501 samples, val on 2510 samples, with batch size 24.
Epoch 1/30
104/104 [==============================] - 372s 4s/step - loss: 1841.9102 - val_loss: 584.9368
Epoch 2/30
104/104 [==============================] - 349s 3s/step - loss: 233.1023 - val_loss: 178.3483
Epoch 3/30
104/104 [==============================] - 352s 3s/step - loss: 106.0130 - val_loss: 93.0495
Epoch 4/30
104/104 [==============================] - 339s 3s/step - loss: 68.8328 - val_loss: 62.0525
Epoch 5/30
104/104 [==============================] - 351s 3s/step - loss: 52.6168 - val_loss: 49.2507
Epoch 6/30
104/104 [==============================] - 345s 3s/step - loss: 44.1594 - val_loss: 41.3564
Epoch 7/30
104/104 [==============================] - 348s 3s/step - loss: 38.0400 - val_loss: 36.4621
Epoch 8/30
104/104 [==============================] - 345s 3s/step - loss: 34.5487 - val_loss: 34.1518
Epoch 9/30
104/104 [==============================] - 352s 3s/step - loss: 31.6726 - val_loss: 32.2504
Epoch 10/30
104/104 [==============================] - 345s 3s/step - loss: 29.4600 - val_loss: 30.4219
Epoch 11/30
104/104 [==============================] - 348s 3s/step - loss: 28.1893 - val_loss: 28.2912
Epoch 12/30
104/104 [==============================] - 343s 3s/step - loss: 26.8196 - val_loss: 26.9538
Epoch 13/30
104/104 [==============================] - 344s 3s/step - loss: 25.6440 - val_loss: 27.3274
Epoch 14/30
104/104 [==============================] - 347s 3s/step - loss: 24.8728 - val_loss: 25.1862
Epoch 15/30
104/104 [==============================] - 344s 3s/step - loss: 24.3172 - val_loss: 24.9123
Epoch 16/30
104/104 [==============================] - 349s 3s/step - loss: 23.2196 - val_loss: 24.0410
Epoch 17/30
104/104 [==============================] - 345s 3s/step - loss: 22.7313 - val_loss: 24.4969
Epoch 18/30
104/104 [==============================] - 347s 3s/step - loss: 21.9372 - val_loss: 24.5070
Epoch 19/30
104/104 [==============================] - 345s 3s/step - loss: 22.0248 - val_loss: 23.5757
Epoch 20/30
104/104 [==============================] - 348s 3s/step - loss: 21.1927 - val_loss: 23.4338
Epoch 21/30
104/104 [==============================] - 343s 3s/step - loss: 20.5408 - val_loss: 22.5973
Epoch 22/30
104/104 [==============================] - 346s 3s/step - loss: 20.7698 - val_loss: 21.9262
Epoch 23/30
104/104 [==============================] - 347s 3s/step - loss: 20.0793 - val_loss: 22.9803
Epoch 24/30
104/104 [==============================] - 344s 3s/step - loss: 19.7196 - val_loss: 24.5589
Epoch 25/30
104/104 [==============================] - 347s 3s/step - loss: 19.7269 - val_loss: 23.0470
Epoch 26/30
104/104 [==============================] - 345s 3s/step - loss: 19.2466 - val_loss: 22.0419
Epoch 27/30
104/104 [==============================] - 347s 3s/step - loss: 19.2453 - val_loss: 20.5318
Epoch 28/30
104/104 [==============================] - 345s 3s/step - loss: 18.7954 - val_loss: 22.2814
Epoch 29/30
104/104 [==============================] - 349s 3s/step - loss: 18.5808 - val_loss: 20.9849
Epoch 30/30
104/104 [==============================] - 343s 3s/step - loss: 18.6739 - val_loss: 21.3272

loaded weights logs/000/test_small_mobilenet_trained_weights_stage_1.h5
aeroplane: 0.1098
bicycle: 0.2156
bird: 0.1051
boat: 0.0531
bottle: 0.0841
bus: 0.2225
car: 0.3507
cat: 0.2220
chair: 0.0120
cow: 0.1111
diningtable: 0.0111
dog: 0.0835
horse: 0.2800
motorbike: 0.1438
person: 0.2900
pottedplant: 0.0277
sheep: 0.0231
sofa: 0.0731
train: 0.1961
tvmonitor: 0.2336
mAP: 0.1424

Train on 2501 samples, val on 2510 samples, with batch size 18.
Epoch 31/60
138/138 [==============================] - 373s 3s/step - loss: 17.2653 - val_loss: 18.9736
Epoch 32/60
138/138 [==============================] - 350s 3s/step - loss: 16.5153 - val_loss: 18.6913
Epoch 33/60
138/138 [==============================] - 354s 3s/step - loss: 16.0926 - val_loss: 18.3441
Epoch 34/60
138/138 [==============================] - 350s 3s/step - loss: 16.0979 - val_loss: 18.6940
Epoch 35/60
138/138 [==============================] - 354s 3s/step - loss: 15.9652 - val_loss: 18.0777
Epoch 36/60
138/138 [==============================] - 350s 3s/step - loss: 15.6942 - val_loss: 18.3320
Epoch 37/60
138/138 [==============================] - 352s 3s/step - loss: 15.7407 - val_loss: 18.4364
Epoch 38/60
138/138 [==============================] - 348s 3s/step - loss: 15.3799 - val_loss: 18.4722

Epoch 00038: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.
Epoch 39/60
138/138 [==============================] - 351s 3s/step - loss: 15.3952 - val_loss: 17.9000
Epoch 40/60
138/138 [==============================] - 354s 3s/step - loss: 15.0296 - val_loss: 18.1178
Epoch 41/60
138/138 [==============================] - 349s 3s/step - loss: 15.2092 - val_loss: 18.0781
Epoch 42/60
138/138 [==============================] - 357s 3s/step - loss: 14.6681 - val_loss: 18.0192

Epoch 00042: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.
Epoch 43/60
138/138 [==============================] - 350s 3s/step - loss: 15.0075 - val_loss: 17.9703
Epoch 44/60
138/138 [==============================] - 354s 3s/step - loss: 14.9870 - val_loss: 17.6119
Epoch 45/60
138/138 [==============================] - 350s 3s/step - loss: 14.9729 - val_loss: 17.9633
Epoch 46/60
138/138 [==============================] - 355s 3s/step - loss: 14.8421 - val_loss: 17.8016
Epoch 47/60
138/138 [==============================] - 350s 3s/step - loss: 14.6332 - val_loss: 18.0249

Epoch 00047: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.
Epoch 48/60
138/138 [==============================] - 353s 3s/step - loss: 14.7527 - val_loss: 17.6316
Epoch 49/60
138/138 [==============================] - 350s 3s/step - loss: 14.9005 - val_loss: 18.0907
Epoch 50/60
138/138 [==============================] - 351s 3s/step - loss: 15.1816 - val_loss: 17.9436

Epoch 00050: ReduceLROnPlateau reducing learning rate to 1.0000000116860975e-08.
Epoch 51/60
138/138 [==============================] - 354s 3s/step - loss: 14.8241 - val_loss: 18.0235
Epoch 52/60
138/138 [==============================] - 349s 3s/step - loss: 14.9498 - val_loss: 17.9423
Epoch 53/60
138/138 [==============================] - 356s 3s/step - loss: 14.9167 - val_loss: 17.6956

Epoch 00053: ReduceLROnPlateau reducing learning rate to 9.999999939225292e-10.
Epoch 54/60
138/138 [==============================] - 350s 3s/step - loss: 14.9113 - val_loss: 18.1160
Epoch 55/60
138/138 [==============================] - 354s 3s/step - loss: 14.6028 - val_loss: 17.8103
Epoch 56/60
138/138 [==============================] - 351s 3s/step - loss: 15.1409 - val_loss: 17.9814

Epoch 00056: ReduceLROnPlateau reducing learning rate to 9.999999717180686e-11.
Epoch 57/60
138/138 [==============================] - 355s 3s/step - loss: 14.7489 - val_loss: 18.1139
Epoch 58/60
138/138 [==============================] - 351s 3s/step - loss: 14.9548 - val_loss: 17.7809
Epoch 59/60
138/138 [==============================] - 353s 3s/step - loss: 14.8293 - val_loss: 17.8859

Epoch 00059: ReduceLROnPlateau reducing learning rate to 9.99999943962493e-12.
Epoch 60/60
138/138 [==============================] - 350s 3s/step - loss: 14.6456 - val_loss: 18.1181

loaded weights logs/000/test_small_mobilenet_trained_weights_final.h5
aeroplane: 0.3272
bicycle: 0.4150
bird: 0.2088
boat: 0.1330
bottle: 0.1451
bus: 0.3786
car: 0.5157
cat: 0.4705
chair: 0.0774
cow: 0.2441
diningtable: 0.1640
dog: 0.3254
horse: 0.4189
motorbike: 0.3938
person: 0.4083
pottedplant: 0.0605
sheep: 0.1305
sofa: 0.3673
train: 0.4099
tvmonitor: 0.2680
mAP: 0.2931
