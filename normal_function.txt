Train on 2501 samples, val on 2510 samples, with batch size 24.
Epoch 1/30
104/104 [==============================] - 373s 4s/step - loss: 1519.8402 - val_loss: 449.6320
Epoch 2/30
104/104 [==============================] - 347s 3s/step - loss: 187.9007 - val_loss: 145.2477
Epoch 3/30
104/104 [==============================] - 345s 3s/step - loss: 90.9391 - val_loss: 84.5205
Epoch 4/30
104/104 [==============================] - 338s 3s/step - loss: 61.9110 - val_loss: 60.0243
Epoch 5/30
104/104 [==============================] - 341s 3s/step - loss: 48.6118 - val_loss: 44.2039
Epoch 6/30
104/104 [==============================] - 340s 3s/step - loss: 41.0085 - val_loss: 40.8619
Epoch 7/30
104/104 [==============================] - 345s 3s/step - loss: 36.4655 - val_loss: 36.2770
Epoch 8/30
104/104 [==============================] - 341s 3s/step - loss: 33.5188 - val_loss: 32.4410
Epoch 9/30
104/104 [==============================] - 339s 3s/step - loss: 31.1596 - val_loss: 31.1304
Epoch 10/30
104/104 [==============================] - 338s 3s/step - loss: 29.2378 - val_loss: 29.1073
Epoch 11/30
104/104 [==============================] - 340s 3s/step - loss: 27.8124 - val_loss: 28.2801
Epoch 12/30
104/104 [==============================] - 339s 3s/step - loss: 26.5640 - val_loss: 26.8003
Epoch 13/30
104/104 [==============================] - 339s 3s/step - loss: 26.0645 - val_loss: 27.3084
Epoch 14/30
104/104 [==============================] - 339s 3s/step - loss: 24.9713 - val_loss: 25.1680
Epoch 15/30
104/104 [==============================] - 341s 3s/step - loss: 24.0487 - val_loss: 25.1703
Epoch 16/30
104/104 [==============================] - 343s 3s/step - loss: 23.1128 - val_loss: 23.5798
Epoch 17/30
104/104 [==============================] - 342s 3s/step - loss: 23.0054 - val_loss: 23.6594
Epoch 18/30
104/104 [==============================] - 342s 3s/step - loss: 22.2198 - val_loss: 22.8624
Epoch 19/30
104/104 [==============================] - 341s 3s/step - loss: 21.4834 - val_loss: 23.8901
Epoch 20/30
104/104 [==============================] - 341s 3s/step - loss: 21.0336 - val_loss: 22.2798
Epoch 21/30
104/104 [==============================] - 347s 3s/step - loss: 21.2966 - val_loss: 23.0586
Epoch 22/30
104/104 [==============================] - 343s 3s/step - loss: 20.4396 - val_loss: 22.2734
Epoch 23/30
104/104 [==============================] - 339s 3s/step - loss: 20.3530 - val_loss: 22.9839
Epoch 24/30
104/104 [==============================] - 339s 3s/step - loss: 19.8257 - val_loss: 21.7424
Epoch 25/30
104/104 [==============================] - 338s 3s/step - loss: 19.7366 - val_loss: 22.9862
Epoch 26/30
104/104 [==============================] - 339s 3s/step - loss: 19.4321 - val_loss: 22.5982
Epoch 27/30
104/104 [==============================] - 338s 3s/step - loss: 19.3779 - val_loss: 22.3096
Epoch 28/30
104/104 [==============================] - 338s 3s/step - loss: 18.9595 - val_loss: 20.2936
Epoch 29/30
104/104 [==============================] - 338s 3s/step - loss: 18.7340 - val_loss: 21.9377
Epoch 30/30
104/104 [==============================] - 339s 3s/step - loss: 18.2993 - val_loss: 20.5572

logs/000/test_fake_trained_weights_stage_1.h5
aeroplane: 0.1444
bicycle: 0.1982
bird: 0.1041
boat: 0.0416
bottle: 0.0686
bus: 0.2586
car: 0.3771
cat: 0.1945
chair: 0.0223
cow: 0.2255
diningtable: 0.0422
dog: 0.0719
horse: 0.2763
motorbike: 0.2278
person: 0.2477
pottedplant: 0.0149
sheep: 0.0331
sofa: 0.0636
train: 0.3178
tvmonitor: 0.1235
mAP: 0.1527

Train on 2501 samples, val on 2510 samples, with batch size 20.
Epoch 31/60
125/125 [==============================] - 360s 3s/step - loss: 17.2720 - val_loss: 18.9976
Epoch 32/60
125/125 [==============================] - 344s 3s/step - loss: 16.4166 - val_loss: 18.7416
Epoch 33/60
125/125 [==============================] - 343s 3s/step - loss: 16.1910 - val_loss: 18.6125
Epoch 34/60
125/125 [==============================] - 342s 3s/step - loss: 15.8414 - val_loss: 18.3274
Epoch 35/60
125/125 [==============================] - 343s 3s/step - loss: 15.8566 - val_loss: 18.4406
Epoch 36/60
125/125 [==============================] - 345s 3s/step - loss: 15.8046 - val_loss: 18.1622
Epoch 37/60
125/125 [==============================] - 342s 3s/step - loss: 15.5341 - val_loss: 18.4857
Epoch 38/60
125/125 [==============================] - 344s 3s/step - loss: 15.4451 - val_loss: 18.6022
Epoch 39/60
125/125 [==============================] - 343s 3s/step - loss: 15.3216 - val_loss: 18.2773

Epoch 00039: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.
Epoch 40/60
125/125 [==============================] - 342s 3s/step - loss: 15.2642 - val_loss: 17.6162
Epoch 41/60
125/125 [==============================] - 343s 3s/step - loss: 14.8583 - val_loss: 18.2192
Epoch 42/60
125/125 [==============================] - 344s 3s/step - loss: 15.0341 - val_loss: 18.1253
Epoch 43/60
125/125 [==============================] - 344s 3s/step - loss: 14.9388 - val_loss: 18.0354

Epoch 00043: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.
Epoch 44/60
125/125 [==============================] - 343s 3s/step - loss: 14.8675 - val_loss: 18.0442
Epoch 45/60
125/125 [==============================] - 342s 3s/step - loss: 14.8913 - val_loss: 18.1114
Epoch 46/60
125/125 [==============================] - 344s 3s/step - loss: 15.0605 - val_loss: 17.7981

Epoch 00046: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.
Epoch 47/60
125/125 [==============================] - 343s 3s/step - loss: 14.8824 - val_loss: 18.3624
Epoch 48/60
125/125 [==============================] - 343s 3s/step - loss: 14.7821 - val_loss: 17.9200
Epoch 49/60
125/125 [==============================] - 346s 3s/step - loss: 14.7976 - val_loss: 17.8607

Epoch 00049: ReduceLROnPlateau reducing learning rate to 1.0000000116860975e-08.
Epoch 50/60
125/125 [==============================] - 349s 3s/step - loss: 15.0042 - val_loss: 18.2002
Epoch 51/60
125/125 [==============================] - 349s 3s/step - loss: 14.7981 - val_loss: 17.8739
Epoch 52/60
125/125 [==============================] - 350s 3s/step - loss: 14.8763 - val_loss: 18.0115

Epoch 00052: ReduceLROnPlateau reducing learning rate to 9.999999939225292e-10.
Epoch 53/60
125/125 [==============================] - 349s 3s/step - loss: 14.9354 - val_loss: 18.3152
Epoch 54/60
125/125 [==============================] - 351s 3s/step - loss: 15.0223 - val_loss: 17.8491
Epoch 55/60
125/125 [==============================] - 350s 3s/step - loss: 14.8799 - val_loss: 18.0595

Epoch 00055: ReduceLROnPlateau reducing learning rate to 9.999999717180686e-11.
Epoch 56/60
125/125 [==============================] - 349s 3s/step - loss: 15.1218 - val_loss: 17.9060
Epoch 57/60
125/125 [==============================] - 349s 3s/step - loss: 14.7614 - val_loss: 18.0540
Epoch 58/60
125/125 [==============================] - 350s 3s/step - loss: 14.7306 - val_loss: 17.7294

Epoch 00058: ReduceLROnPlateau reducing learning rate to 9.99999943962493e-12.
Epoch 59/60
125/125 [==============================] - 351s 3s/step - loss: 14.8867 - val_loss: 18.0071
Epoch 60/60
125/125 [==============================] - 350s 3s/step - loss: 14.7230 - val_loss: 17.8713

loaded weights logs/000/test_fake_trained_weights_final.h5
aeroplane: 0.3240
bicycle: 0.4091
bird: 0.2162
boat: 0.1397
bottle: 0.1518
bus: 0.3494
car: 0.5111
cat: 0.4520
chair: 0.0543
cow: 0.2734
diningtable: 0.1286
dog: 0.2910
horse: 0.4117
motorbike: 0.4259
person: 0.4057
pottedplant: 0.0554
sheep: 0.1046
sofa: 0.3444
train: 0.4111
tvmonitor: 0.2667
mAP: 0.2863