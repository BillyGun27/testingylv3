alpha 0 
Train on 2501 samples, val on 2510 samples, with batch size 24.
Epoch 1/30
104/104 [==============================] - 533s 5s/step - loss: 1285.8585 - val_loss: 254.9799
Epoch 2/30
104/104 [==============================] - 500s 5s/step - loss: 150.3300 - val_loss: 104.0471
Epoch 3/30
104/104 [==============================] - 496s 5s/step - loss: 78.5903 - val_loss: 73.4586
Epoch 4/30
104/104 [==============================] - 482s 5s/step - loss: 53.8701 - val_loss: 55.7099
Epoch 5/30
104/104 [==============================] - 502s 5s/step - loss: 39.5378 - val_loss: 46.0664
Epoch 6/30
104/104 [==============================] - 501s 5s/step - loss: 32.2193 - val_loss: 46.5155
Epoch 7/30
104/104 [==============================] - 497s 5s/step - loss: 27.1188 - val_loss: 41.3088
Epoch 8/30
104/104 [==============================] - 497s 5s/step - loss: 23.5023 - val_loss: 38.4027
Epoch 9/30
104/104 [==============================] - 493s 5s/step - loss: 21.1340 - val_loss: 34.2312
Epoch 10/30
104/104 [==============================] - 503s 5s/step - loss: 19.0155 - val_loss: 35.9919
Epoch 11/30
104/104 [==============================] - 507s 5s/step - loss: 17.9324 - val_loss: 34.0916
Epoch 12/30
104/104 [==============================] - 506s 5s/step - loss: 16.2772 - val_loss: 35.6602
Epoch 13/30
104/104 [==============================] - 501s 5s/step - loss: 16.0098 - val_loss: 34.7541
Epoch 14/30
104/104 [==============================] - 502s 5s/step - loss: 14.7259 - val_loss: 40.3626
Epoch 15/30
104/104 [==============================] - 502s 5s/step - loss: 23.0802 - val_loss: 33.6689
Epoch 16/30
104/104 [==============================] - 501s 5s/step - loss: 26.2498 - val_loss: 33.5689
Epoch 17/30
104/104 [==============================] - 499s 5s/step - loss: 20.1751 - val_loss: 37.0162
Epoch 18/30
104/104 [==============================] - 499s 5s/step - loss: 17.5940 - val_loss: 29.8353
Epoch 19/30
104/104 [==============================] - 503s 5s/step - loss: 15.9770 - val_loss: 34.0211
Epoch 20/30
104/104 [==============================] - 497s 5s/step - loss: 15.0142 - val_loss: 38.6224
Epoch 21/30
104/104 [==============================] - 499s 5s/step - loss: 14.8315 - val_loss: 42.2952
Epoch 22/30
104/104 [==============================] - 500s 5s/step - loss: 14.2078 - val_loss: 36.7588
Epoch 23/30
104/104 [==============================] - 501s 5s/step - loss: 13.4158 - val_loss: 37.4477
Epoch 24/30
104/104 [==============================] - 498s 5s/step - loss: 13.4372 - val_loss: 35.8958
Epoch 25/30
104/104 [==============================] - 501s 5s/step - loss: 12.5211 - val_loss: 42.3112
Epoch 26/30
104/104 [==============================] - 500s 5s/step - loss: 12.3828 - val_loss: 40.8860
Epoch 27/30
104/104 [==============================] - 499s 5s/step - loss: 12.6398 - val_loss: 38.1945
Epoch 28/30
104/104 [==============================] - 497s 5s/step - loss: 17.1009 - val_loss: 37.3391
Epoch 29/30
104/104 [==============================] - 502s 5s/step - loss: 17.7571 - val_loss: 38.2577
Epoch 30/30
104/104 [==============================] - 498s 5s/step - loss: 14.7625 - val_loss: 36.2055

loaded weights logs/000/test_small_mobilenet_trained_weights_stage_1.h5
aeroplane: 0.0241
bicycle: 0.0015
bird: 0.0101
boat: 0.0045
bottle: 0.0000
bus: 0.0129
car: 0.1178
cat: 0.0159
chair: 0.0063
cow: 0.0000
diningtable: 0.0044
dog: 0.0021
horse: 0.0000
motorbike: 0.0433
person: 0.1406
pottedplant: 0.0000
sheep: 0.0002
sofa: 0.0003
train: 0.0080
tvmonitor: 0.0045
mAP: 0.0198

Train on 2501 samples, val on 2510 samples, with batch size 18.
Epoch 31/60
138/138 [==============================] - 558s 4s/step - loss: 22.8223 - val_loss: 26.8850
Epoch 32/60
138/138 [==============================] - 521s 4s/step - loss: 20.0996 - val_loss: 25.0252
Epoch 33/60
138/138 [==============================] - 523s 4s/step - loss: 18.1125 - val_loss: 24.6686
Epoch 34/60
138/138 [==============================] - 522s 4s/step - loss: 18.1304 - val_loss: 27.7345
Epoch 35/60
138/138 [==============================] - 522s 4s/step - loss: 21.4830 - val_loss: 23.1149
Epoch 36/60
138/138 [==============================] - 523s 4s/step - loss: 18.5817 - val_loss: 28.6552
Epoch 37/60
138/138 [==============================] - 522s 4s/step - loss: 16.0403 - val_loss: 32.4488
Epoch 38/60
138/138 [==============================] - 517s 4s/step - loss: 17.0560 - val_loss: 23.6390

Epoch 00038: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.
Epoch 39/60
138/138 [==============================] - 521s 4s/step - loss: 16.0732 - val_loss: 31.9207
Epoch 40/60
138/138 [==============================] - 521s 4s/step - loss: 22.4218 - val_loss: 26.8645
Epoch 41/60
138/138 [==============================] - 523s 4s/step - loss: 19.5044 - val_loss: 21.4128
Epoch 42/60
138/138 [==============================] - 520s 4s/step - loss: 23.3242 - val_loss: 21.4479
Epoch 43/60
138/138 [==============================] - 521s 4s/step - loss: 21.1676 - val_loss: 28.8103
Epoch 44/60
138/138 [==============================] - 522s 4s/step - loss: 19.7844 - val_loss: 26.0511

Epoch 00044: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.
Epoch 45/60
138/138 [==============================] - 527s 4s/step - loss: 20.7255 - val_loss: 20.8814
Epoch 46/60
138/138 [==============================] - 521s 4s/step - loss: 19.2638 - val_loss: 23.3937
Epoch 47/60
138/138 [==============================] - 527s 4s/step - loss: 20.7080 - val_loss: 25.7704
Epoch 48/60
138/138 [==============================] - 525s 4s/step - loss: 21.3505 - val_loss: 26.5634

Epoch 00048: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.
Epoch 49/60
138/138 [==============================] - 526s 4s/step - loss: 25.4935 - val_loss: 26.2806
Epoch 50/60
138/138 [==============================] - 519s 4s/step - loss: 22.6016 - val_loss: 25.9523
Epoch 51/60
138/138 [==============================] - 520s 4s/step - loss: 21.3969 - val_loss: 26.5810

Epoch 00051: ReduceLROnPlateau reducing learning rate to 1.0000000116860975e-08.
Epoch 52/60
138/138 [==============================] - 522s 4s/step - loss: 20.7266 - val_loss: 26.5484
Epoch 53/60
138/138 [==============================] - 520s 4s/step - loss: 21.6118 - val_loss: 26.5267
Epoch 54/60
138/138 [==============================] - 518s 4s/step - loss: 23.3975 - val_loss: 26.9740

Epoch 00054: ReduceLROnPlateau reducing learning rate to 9.999999939225292e-10.
Epoch 55/60
138/138 [==============================] - 521s 4s/step - loss: 23.8159 - val_loss: 26.9811
Epoch 56/60
138/138 [==============================] - 522s 4s/step - loss: 23.7127 - val_loss: 26.8700
Epoch 57/60
138/138 [==============================] - 523s 4s/step - loss: 22.2441 - val_loss: 26.9440

Epoch 00057: ReduceLROnPlateau reducing learning rate to 9.999999717180686e-11.
Epoch 58/60
138/138 [==============================] - 525s 4s/step - loss: 16.7924 - val_loss: 26.3915
Epoch 59/60
138/138 [==============================] - 523s 4s/step - loss: 22.2947 - val_loss: 26.3912
Epoch 60/60
138/138 [==============================] - 524s 4s/step - loss: 20.2663 - val_loss: 26.3089

Epoch 00060: ReduceLROnPlateau reducing learning rate to 9.99999943962493e-12.

aeroplane: 0.1386
bicycle: 0.0849
bird: 0.0583
boat: 0.0105
bottle: 0.0438
bus: 0.0943
car: 0.4331
cat: 0.2142
chair: 0.0177
cow: 0.0374
diningtable: 0.0828
dog: 0.0418
horse: 0.2312
motorbike: 0.1428
person: 0.2819
pottedplant: 0.0025
sheep: 0.1139
sofa: 0.0568
train: 0.1201
tvmonitor: 0.2225
mAP: 0.1214